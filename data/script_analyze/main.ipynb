{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7289df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dungu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dungu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dungu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932fe2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main cast characters\n",
    "MAIN_CAST = ['Sheldon', 'Penny', 'Amy', 'Howard', 'Bernadette', 'Leonard', 'Raj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de55a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully with 54406 rows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "episode_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dialogue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "person_scene",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "series",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "episode",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "episode_name_only",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b3920ab8-ae29-4dab-9f1c-7e3622eded1c",
       "rows": [
        [
         "0",
         "Series 01 Episode 01 – Pilot Episode",
         " A corridor at a sperm bank.",
         "Scene",
         "1.0",
         "1.0",
         "Pilot Episode"
        ],
        [
         "1",
         "Series 01 Episode 01 – Pilot Episode",
         " So if a photon is directed through a plane with two slits in it and either slit is observed it will not go through both slits. If it’s unobserved it will, however, if it’s observed after it’s left the plane but before it hits its target, it will not have gone through both slits.",
         "Sheldon",
         "1.0",
         "1.0",
         "Pilot Episode"
        ],
        [
         "2",
         "Series 01 Episode 01 – Pilot Episode",
         " Agreed, what’s your point?",
         "Leonard",
         "1.0",
         "1.0",
         "Pilot Episode"
        ],
        [
         "3",
         "Series 01 Episode 01 – Pilot Episode",
         " There’s no point, I just think it’s a good idea for a tee-shirt. ",
         "Sheldon",
         "1.0",
         "1.0",
         "Pilot Episode"
        ],
        [
         "4",
         "Series 01 Episode 01 – Pilot Episode",
         " Excuse me?",
         "Leonard",
         "1.0",
         "1.0",
         "Pilot Episode"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>series</th>\n",
       "      <th>episode</th>\n",
       "      <th>episode_name_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>Scene</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pilot Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>So if a photon is directed through a plane wi...</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pilot Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pilot Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>There’s no point, I just think it’s a good id...</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pilot Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pilot Episode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           episode_name  \\\n",
       "0  Series 01 Episode 01 – Pilot Episode   \n",
       "1  Series 01 Episode 01 – Pilot Episode   \n",
       "2  Series 01 Episode 01 – Pilot Episode   \n",
       "3  Series 01 Episode 01 – Pilot Episode   \n",
       "4  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                            dialogue person_scene  series  \\\n",
       "0                        A corridor at a sperm bank.        Scene     1.0   \n",
       "1   So if a photon is directed through a plane wi...      Sheldon     1.0   \n",
       "2                         Agreed, what’s your point?      Leonard     1.0   \n",
       "3   There’s no point, I just think it’s a good id...      Sheldon     1.0   \n",
       "4                                         Excuse me?      Leonard     1.0   \n",
       "\n",
       "   episode episode_name_only  \n",
       "0      1.0     Pilot Episode  \n",
       "1      1.0     Pilot Episode  \n",
       "2      1.0     Pilot Episode  \n",
       "3      1.0     Pilot Episode  \n",
       "4      1.0     Pilot Episode  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "def load_dialogue_data(file_path):\n",
    "    \"\"\"Load the dialogue data from CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully with {len(df)} rows.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "file_path = 'big_bang_scripts.csv'\n",
    "dialogue_df = load_dialogue_data(file_path)\n",
    "\n",
    "# Display the first few rows to confirm the data structure\n",
    "dialogue_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88b4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to clean text\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing punctuation, converting to lowercase, and removing stop words.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Tokenize and convert to lowercase\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Get English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Additional stop words specific to the script context\n",
    "    additional_stop_words = {'oh', 'uh', 'um', 'like', 'just', 'well', 'yeah', 'okay', 'ok', 'so', 'hey', 'oh', 'ah', \n",
    "                            'gonna', 'wanna', 'gotta', 'would', 'could', 'should', 'i', 'you', 'he', 'she', 'it', 'we', \n",
    "                            'they', 'me', 'him', 'her', 'them', 'my', 'your', 'his', 'its', 'our', 'their', 'that', \n",
    "                            'this', 'what', 'going', 'get', 'got', 'do', 'does', 'did', 'doing', 'don', 'doesn', \n",
    "                            'didn', 'is', 'am', 'are', 'was', 'were', 'been', 'being', 'have', 'has', 'had', 'having', 'na', 'gon'}\n",
    "    stop_words.update(additional_stop_words)\n",
    "    \n",
    "    # Remove stop words and non-alphabetic characters\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words and len(word) > 1]\n",
    "    \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569547ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue_data(df):\n",
    "    \"\"\"Process dialogue data to extract words used by each main cast character in each series.\"\"\"\n",
    "    if 'person_scene' not in df.columns or 'dialogue' not in df.columns or 'series' not in df.columns:\n",
    "        print(\"Required columns not found in the dataframe.\")\n",
    "        return None\n",
    "    \n",
    "    # Filter for main cast and exclude scene descriptions\n",
    "    df_dialogue = df[(df['person_scene'].isin(MAIN_CAST))]\n",
    "    \n",
    "    # Check if we have any dialogue for the main cast\n",
    "    if len(df_dialogue) == 0:\n",
    "        print(\"No dialogue found for the specified main cast. Check character names in the dataset.\")\n",
    "        # Print all unique character names to help troubleshoot\n",
    "        print(\"Available characters in the dataset:\", df['person_scene'].unique())\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(df_dialogue)} dialogue lines for the main cast.\")\n",
    "    \n",
    "    # Initialize structures to store word counts\n",
    "    character_series_words = {character: {} for character in MAIN_CAST}\n",
    "    \n",
    "    # Process each row in the dataframe\n",
    "    for _, row in df_dialogue.iterrows():\n",
    "        character = row['person_scene']\n",
    "        series = row['series']\n",
    "        dialogue = row['dialogue']\n",
    "        \n",
    "        # Clean the dialogue text\n",
    "        words = clean_text(dialogue)\n",
    "        \n",
    "        # Update the character's word count for this series\n",
    "        if series not in character_series_words[character]:\n",
    "            character_series_words[character][series] = []\n",
    "        \n",
    "        character_series_words[character][series].extend(words)\n",
    "    \n",
    "    return character_series_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e1ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top words for each character by series\n",
    "def get_top_words(character_series_words, top_n=15):\n",
    "    \"\"\"Get the top N most common words for each main cast character by series.\"\"\"\n",
    "    top_words_data = []\n",
    "    id_counter = 1\n",
    "    \n",
    "    for character in MAIN_CAST:\n",
    "        if character not in character_series_words:\n",
    "            continue\n",
    "            \n",
    "        for series in character_series_words[character]:\n",
    "            words = character_series_words[character][series]\n",
    "            word_counts = Counter(words)\n",
    "            \n",
    "            # Get top N words\n",
    "            top_words = word_counts.most_common(top_n)\n",
    "            \n",
    "            # Add to the list\n",
    "            for word, count in top_words:\n",
    "                top_words_data.append({\n",
    "                    'id': id_counter,\n",
    "                    'character': character,\n",
    "                    'series': series,\n",
    "                    'word': word,\n",
    "                    'count': count\n",
    "                })\n",
    "                id_counter += 1\n",
    "    \n",
    "    return pd.DataFrame(top_words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798e44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words(character_series_words, top_n=15):\n",
    "    \"\"\"Find words that are unique to each main cast character (used more frequently by them than others).\"\"\"\n",
    "    # First, get all words used by each character across all series\n",
    "    character_words = {character: [] for character in MAIN_CAST}\n",
    "    all_words = []\n",
    "    \n",
    "    for character in MAIN_CAST:\n",
    "        if character not in character_series_words:\n",
    "            continue\n",
    "            \n",
    "        for series in character_series_words[character]:\n",
    "            character_words[character].extend(character_series_words[character][series])\n",
    "        all_words.extend(character_words[character])\n",
    "    \n",
    "    # Calculate total word frequencies\n",
    "    total_word_freq = Counter(all_words)\n",
    "    \n",
    "    # Calculate uniqueness scores (TF-IDF inspired)\n",
    "    unique_words_data = []\n",
    "    id_counter = 1\n",
    "    \n",
    "    for character in MAIN_CAST:\n",
    "        if character not in character_words or not character_words[character]:\n",
    "            continue\n",
    "            \n",
    "        char_word_freq = Counter(character_words[character])\n",
    "        \n",
    "        # Calculate uniqueness score for each word\n",
    "        # (frequency of word for this character / frequency of word across all characters)\n",
    "        uniqueness_scores = {}\n",
    "        for word, count in char_word_freq.items():\n",
    "            # Skip very rare words (used less than 3 times by this character)\n",
    "            if count < 3:\n",
    "                continue\n",
    "            \n",
    "            # Calculate uniqueness score - higher when the word is used more by this character\n",
    "            # and less by others\n",
    "            uniqueness_scores[word] = (count / total_word_freq[word] * count) if total_word_freq[word] > 0 else 0\n",
    "        \n",
    "        # Get top N unique words\n",
    "        top_unique_words = sorted(uniqueness_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        \n",
    "        # Add to the list\n",
    "        for word, score in top_unique_words:\n",
    "            unique_words_data.append({\n",
    "                'id': id_counter,\n",
    "                'character': character,\n",
    "                'word': word,\n",
    "                'count': char_word_freq[word],\n",
    "                'uniqueness_score': score\n",
    "            })\n",
    "            id_counter += 1\n",
    "    \n",
    "    return pd.DataFrame(unique_words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e28033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create directories for output files.\"\"\"\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    os.makedirs('output/by_season', exist_ok=True)\n",
    "    os.makedirs('output/by_character', exist_ok=True)\n",
    "    print(\"Output directories created.\")\n",
    "\n",
    "# Save results to CSV\n",
    "def save_results(top_words_df, unique_words_df):\n",
    "    \"\"\"Save the analysis results to CSV files.\"\"\"\n",
    "    # Save the overall top words\n",
    "    top_words_df.to_csv('output/main_cast_top_words.csv', index=False)\n",
    "    print(\"Saved top words to output/main_cast_top_words.csv\")\n",
    "    \n",
    "    # Save the unique words\n",
    "    unique_words_df.to_csv('output/main_cast_unique_words.csv', index=False)\n",
    "    print(\"Saved unique words to output/main_cast_unique_words.csv\")\n",
    "    \n",
    "    # Save top words by season\n",
    "    for series in top_words_df['series'].unique():\n",
    "        series_df = top_words_df[top_words_df['series'] == series]\n",
    "        series_df.to_csv(f'output/by_season/series_{series}_top_words.csv', index=False)\n",
    "        print(f\"Saved Series {series} top words to output/by_season/series_{series}_top_words.csv\")\n",
    "    \n",
    "    # Save top words by character\n",
    "    for character in MAIN_CAST:\n",
    "        if character in top_words_df['character'].values:\n",
    "            char_df = top_words_df[top_words_df['character'] == character]\n",
    "            char_df.to_csv(f'output/by_character/{character}_top_words.csv', index=False)\n",
    "            print(f\"Saved {character}'s top words to output/by_character/{character}_top_words.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abfa3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(top_words_df, unique_words_df):\n",
    "    \"\"\"Create visualizations of the word analysis for main cast.\"\"\"\n",
    "    # Plot top words for each main character\n",
    "    for character in MAIN_CAST:\n",
    "        if character in top_words_df['character'].values:\n",
    "            # Get overall top words for this character\n",
    "            char_df = top_words_df[top_words_df['character'] == character]\n",
    "            word_counts = char_df.groupby('word')['count'].sum().reset_index()\n",
    "            top_15_words = word_counts.sort_values('count', ascending=False).head(15)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.bar(top_15_words['word'], top_15_words['count'])\n",
    "            plt.title(f\"Top 15 Words Used by {character}\")\n",
    "            plt.xlabel(\"Word\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"output/{character}_top_words.png\")\n",
    "            plt.close()\n",
    "    \n",
    "    # Plot unique words for each main character\n",
    "    for character in MAIN_CAST:\n",
    "        if character in unique_words_df['character'].values:\n",
    "            char_df = unique_words_df[unique_words_df['character'] == character].head(15)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.bar(char_df['word'], char_df['uniqueness_score'])\n",
    "            plt.title(f\"Top 15 Unique Words for {character}\")\n",
    "            plt.xlabel(\"Word\")\n",
    "            plt.ylabel(\"Uniqueness Score\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"output/{character}_unique_words.png\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61f77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     \"\"\"Main execution flow.\"\"\"\n",
    "#     # Create output directories\n",
    "#     create_output_dirs()\n",
    "    \n",
    "#     # Process the dialogue data\n",
    "#     character_series_words = process_dialogue_data(dialogue_df)\n",
    "    \n",
    "#     if character_series_words:\n",
    "#         # Get top words for each character by series\n",
    "#         top_words_df = get_top_words(character_series_words)\n",
    "        \n",
    "#         # Get unique words for each character\n",
    "#         unique_words_df = get_unique_words(character_series_words)\n",
    "        \n",
    "#         # Save results to CSV\n",
    "#         save_results(top_words_df, unique_words_df)\n",
    "        \n",
    "#         # Create visualizations\n",
    "#         create_visualizations(top_words_df, unique_words_df)\n",
    "        \n",
    "#         # Display sample of results\n",
    "#         print(\"\\nSample of top words by character and series:\")\n",
    "#         display(top_words_df.head(10))\n",
    "        \n",
    "#         print(\"\\nSample of unique words by character:\")\n",
    "#         display(unique_words_df.head(10))\n",
    "        \n",
    "#         print(\"\\nCharacter statistics:\")\n",
    "#         character_counts = top_words_df['character'].value_counts()\n",
    "#         display(character_counts)\n",
    "        \n",
    "#         print(\"\\nAnalysis complete!\")\n",
    "#     else:\n",
    "#         print(\"Failed to process dialogue data.\")\n",
    "\n",
    "# # Execute the main function\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb34f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created.\n",
      "Found 44967 dialogue lines for the main cast.\n",
      "Saved all seasons uniqueness data with 650 entries to output/season_character_unique_words.csv\n",
      "\n",
      "Verifying entry counts per character per season:\n",
      "    character  season  word_count\n",
      "0         Amy     4.0          10\n",
      "1         Amy     5.0          10\n",
      "2         Amy     6.0          10\n",
      "3         Amy     7.0          10\n",
      "4         Amy     8.0          10\n",
      "5         Amy     9.0          10\n",
      "6         Amy    10.0          10\n",
      "7  Bernadette     3.0          10\n",
      "8  Bernadette     4.0          10\n",
      "9  Bernadette     5.0          10\n",
      "All character-season combinations have 10 or fewer words as expected.\n",
      "\n",
      "Sample of unique words by character and season:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "character",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "season",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rank",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "uniqueness_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "442d8f3b-1572-4e91-bc73-2f5833ec5073",
       "rows": [
        [
         "0",
         "1",
         "Sheldon",
         "1.0",
         "1",
         "knock",
         "64",
         "59.36231884057971"
        ],
        [
         "1",
         "2",
         "Sheldon",
         "1.0",
         "2",
         "leonard",
         "73",
         "32.102409638554214"
        ],
        [
         "2",
         "3",
         "Sheldon",
         "1.0",
         "3",
         "think",
         "47",
         "22.09"
        ],
        [
         "3",
         "4",
         "Sheldon",
         "1.0",
         "4",
         "time",
         "46",
         "19.962264150943398"
        ],
        [
         "4",
         "5",
         "Sheldon",
         "1.0",
         "5",
         "penny",
         "50",
         "17.73049645390071"
        ],
        [
         "5",
         "6",
         "Sheldon",
         "1.0",
         "6",
         "yes",
         "40",
         "16.666666666666668"
        ],
        [
         "6",
         "7",
         "Sheldon",
         "1.0",
         "7",
         "one",
         "45",
         "16.071428571428573"
        ],
        [
         "7",
         "8",
         "Sheldon",
         "1.0",
         "8",
         "course",
         "22",
         "13.82857142857143"
        ],
        [
         "8",
         "9",
         "Sheldon",
         "1.0",
         "9",
         "need",
         "32",
         "13.473684210526315"
        ],
        [
         "9",
         "10",
         "Sheldon",
         "1.0",
         "10",
         "please",
         "22",
         "13.081081081081082"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>character</th>\n",
       "      <th>season</th>\n",
       "      <th>rank</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>uniqueness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>knock</td>\n",
       "      <td>64</td>\n",
       "      <td>59.362319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>leonard</td>\n",
       "      <td>73</td>\n",
       "      <td>32.102410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>think</td>\n",
       "      <td>47</td>\n",
       "      <td>22.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>time</td>\n",
       "      <td>46</td>\n",
       "      <td>19.962264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>penny</td>\n",
       "      <td>50</td>\n",
       "      <td>17.730496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>yes</td>\n",
       "      <td>40</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>one</td>\n",
       "      <td>45</td>\n",
       "      <td>16.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>course</td>\n",
       "      <td>22</td>\n",
       "      <td>13.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>need</td>\n",
       "      <td>32</td>\n",
       "      <td>13.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>please</td>\n",
       "      <td>22</td>\n",
       "      <td>13.081081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id character  season  rank     word  count  uniqueness_score\n",
       "0   1   Sheldon     1.0     1    knock     64         59.362319\n",
       "1   2   Sheldon     1.0     2  leonard     73         32.102410\n",
       "2   3   Sheldon     1.0     3    think     47         22.090000\n",
       "3   4   Sheldon     1.0     4     time     46         19.962264\n",
       "4   5   Sheldon     1.0     5    penny     50         17.730496\n",
       "5   6   Sheldon     1.0     6      yes     40         16.666667\n",
       "6   7   Sheldon     1.0     7      one     45         16.071429\n",
       "7   8   Sheldon     1.0     8   course     22         13.828571\n",
       "8   9   Sheldon     1.0     9     need     32         13.473684\n",
       "9  10   Sheldon     1.0    10   please     22         13.081081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "def get_unique_words_by_season(character_series_words, top_n=10):\n",
    "    \"\"\"Find words that are unique to each main cast character by season.\"\"\"\n",
    "    # Get all seasons with valid data (exclude NaN)\n",
    "    seasons = sorted(set([s for character in character_series_words \n",
    "                       for s in character_series_words[character].keys() \n",
    "                       if not pd.isna(s)]))\n",
    "    \n",
    "    all_results = []\n",
    "    id_counter = 1\n",
    "    \n",
    "    for season in seasons:\n",
    "        # Get all words used by each character in this season\n",
    "        season_character_words = {character: [] for character in MAIN_CAST}\n",
    "        all_season_words = []\n",
    "        \n",
    "        for character in MAIN_CAST:\n",
    "            if character in character_series_words and season in character_series_words[character]:\n",
    "                season_character_words[character] = character_series_words[character][season]\n",
    "                all_season_words.extend(season_character_words[character])\n",
    "        \n",
    "        # Calculate total word frequencies for this season\n",
    "        season_word_freq = Counter(all_season_words)\n",
    "        \n",
    "        # Calculate uniqueness scores for each character in this season\n",
    "        for character in MAIN_CAST:\n",
    "            if not season_character_words[character]:\n",
    "                continue\n",
    "                \n",
    "            char_word_freq = Counter(season_character_words[character])\n",
    "            \n",
    "            # Calculate uniqueness score for each word\n",
    "            uniqueness_scores = {}\n",
    "            for word, count in char_word_freq.items():\n",
    "                # Skip very rare words (used less than 2 times by this character in this season)\n",
    "                if count < 2:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate uniqueness score - higher when the word is used more by this character\n",
    "                # and less by others in this season\n",
    "                uniqueness_scores[word] = (count / season_word_freq[word] * count) if season_word_freq[word] > 0 else 0\n",
    "            \n",
    "            # Get top N unique words for this character in this season\n",
    "            top_unique_words = sorted(uniqueness_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "            \n",
    "            # Add to the results - each word appears exactly once per character per season\n",
    "            for rank, (word, score) in enumerate(top_unique_words, 1):\n",
    "                all_results.append({\n",
    "                    'id': id_counter,\n",
    "                    'character': character,\n",
    "                    'season': season,\n",
    "                    'rank': rank,  # Add rank information (1-10)\n",
    "                    'word': word,\n",
    "                    'count': char_word_freq[word],\n",
    "                    'uniqueness_score': score\n",
    "                })\n",
    "                id_counter += 1\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "def save_season_uniqueness_results(season_uniqueness_df):\n",
    "    \"\"\"Save only the main season-based uniqueness analysis results to CSV.\"\"\"\n",
    "    # Make sure the output directory exists\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    \n",
    "    # Save only the main results file - this contains exactly 10 words per character per season\n",
    "    season_uniqueness_df.to_csv('output/season_character_unique_words.csv', index=False)\n",
    "    print(f\"Saved all seasons uniqueness data with {len(season_uniqueness_df)} entries to output/season_character_unique_words.csv\")\n",
    "    \n",
    "    # Verify the count of entries per character per season\n",
    "    word_counts = season_uniqueness_df.groupby(['character', 'season']).size().reset_index(name='word_count')\n",
    "    print(\"\\nVerifying entry counts per character per season:\")\n",
    "    print(word_counts.head(10))\n",
    "    \n",
    "    # Check if all word counts are 10 or less as expected\n",
    "    if word_counts['word_count'].max() > 10:\n",
    "        print(\"WARNING: Some character-season combinations have more than 10 words!\")\n",
    "    else:\n",
    "        print(\"All character-season combinations have 10 or fewer words as expected.\")\n",
    "\n",
    "# Update the main function to only include the necessary analysis\n",
    "def main():\n",
    "    \"\"\"Main execution flow.\"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    print(\"Output directory created.\")\n",
    "    \n",
    "    # Process the dialogue data\n",
    "    character_series_words = process_dialogue_data(dialogue_df)\n",
    "    \n",
    "    if character_series_words:\n",
    "        # Get unique words by season for each character\n",
    "        season_uniqueness_df = get_unique_words_by_season(character_series_words)\n",
    "        \n",
    "        # Save only the main results file\n",
    "        save_season_uniqueness_results(season_uniqueness_df)\n",
    "        \n",
    "        # Display sample of results\n",
    "        print(\"\\nSample of unique words by character and season:\")\n",
    "        display(season_uniqueness_df.head(10))\n",
    "        \n",
    "        print(\"\\nAnalysis complete!\")\n",
    "    else:\n",
    "        print(\"Failed to process dialogue data.\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
